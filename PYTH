from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
import pandas as pd
import time

# Set up Chrome WebDriver
options = webdriver.ChromeOptions()
options.add_argument("--headless")  # Run in background (optional)
options.add_argument("--disable-blink-features=AutomationControlled")  # Avoid detection

driver = webdriver.Chrome(options=options)

# Open Amazon Laptops Page
url = "https://www.amazon.com/s?k=laptops"
driver.get(url)

# Scroll down to load more results
for _ in range(3):  
    driver.find_element(By.TAG_NAME, "body").send_keys(Keys.END)
    time.sleep(2)  # Wait for content to load

# Extract laptop details
products = []
items = driver.find_elements(By.XPATH, "//div[@data-component-type='s-search-result']")

for item in items:
    try:
        name = item.find_element(By.XPATH, ".//h2/a/span").text
        price = item.find_element(By.XPATH, ".//span[@class='a-price-whole']").text
        rating = item.find_element(By.XPATH, ".//span[@class='a-icon-alt']").text
        reviews = item.find_element(By.XPATH, ".//span[@class='s-link-style']").text

        products.append({"Name": name, "Price ($)": price, "Rating": rating, "Reviews": reviews})
    except:
        continue  # Skip items with missing details

# Save to CSV
df = pd.DataFrame(products)
df.to_csv("amazon_laptops_selenium.csv", index=False)

print("âœ… Scraping complete! Data saved as amazon_laptops_selenium.csv")

driver.quit()
